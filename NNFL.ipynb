{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sarthak-srivastava/Learning-Iterative-Image-Reconstruction/blob/master/NNFL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duWV_bfxXbgZ"
   },
   "source": [
    "Link to the paper: http://www.ais.uni-bonn.de/behnke/papers/ijcai01.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUK7ySBFWdW3"
   },
   "outputs": [],
   "source": [
    "#Lets get started by loading our basic dependencies\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wm5VUmRSOflf"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwYpk88uWslH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "jsc5rrTzQLbd",
    "outputId": "9619b8e5-5b4a-46c5-e038-002b972ebdfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-71e12f4bac70>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/sarthak/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/sarthak/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sarthak/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sarthak/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/sarthak/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I3J37AhQWu5l",
    "outputId": "4b9b4fb5-89af-42b8-c8ce-9595f132da65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = mnist.train.images[:55000,:]\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "eTfWGyvGW61V",
    "outputId": "a5074e7d-b4dc-4343-e619-c6e3d878ecaf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's have a look at a random image\n",
    "RandomNum = random.randint(0,55000)\n",
    "image = x_train[RandomNum].reshape([28,28])\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YT2L7WiIwp9x",
    "outputId": "db30355c-2b0a-44c4-c9fa-31c5a2e380af"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eWGKIeEUuHN-",
    "outputId": "6c44ade2-6328-4e84-808e-3022870261f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "x =[0]*55000\n",
    "image_label = [0]*55000\n",
    "image_train = [0]*55000\n",
    "for i in range(55000):\n",
    "  x[i] = x_train[i].reshape([28,28])\n",
    "  image_label[i] = x_train[i].reshape([784,1])\n",
    "  image_train[i] = resize(x[i], (14,14))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "C-kqpRRKysiu",
    "outputId": "56f1a0e0-6f1a-4bd0-8ea2-9031096dfb89"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_train[RandomNum])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxmupT_xzhrO"
   },
   "outputs": [],
   "source": [
    "for i in range(55000):\n",
    "  image_train[i] = image_train[i].reshape([196,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laDogaoK0AZW"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "from stackrnn import StackRNNCell, StackLSTMCell, RecurrentWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# hyperparameter search on algorithmic patterns\n",
    "\n",
    "n_iterations =55\n",
    "n_min = 2\n",
    "n_max_train = 15\n",
    "n_max_val = 19\n",
    "n_max_test = 60\n",
    "n_img_per_iter = 1000\n",
    "model =\"srnn\"\n",
    "hidden_sizes = [20, 40, 100]\n",
    "hidden_layers = [1]\n",
    "sgd_lrs = [0.1, 0.01, 0.001]\n",
    "n_stacks = [1, 2, 5, 10]\n",
    "ks = [1, 2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  1\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  1\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  2\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  2\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  5\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  5\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  10\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  10\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  1\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  1\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  2\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  2\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  5\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  5\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  10\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  10\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  1\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  1\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  2\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  2\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  5\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  5\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  10\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  20\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  10\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  1\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  1\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  2\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  2\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  5\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  5\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  10\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  10\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  1\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  1\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  2\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  2\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  5\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  5\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  10\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  10\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  1\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  1\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  2\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  2\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  5\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  5\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  10\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  40\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  10\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  1\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  1\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  2\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  2\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  5\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  5\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  10\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.1\n",
      " stacks:  10\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  1\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  1\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  2\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  2\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  5\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  5\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  10\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.01\n",
      " stacks:  10\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  1\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  1\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  2\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  2\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  5\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  5\n",
      " k:  2\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  10\n",
      " k:  1\n",
      "============================================================\n",
      "============================================================\n",
      " units:  100\n",
      " layers:  1\n",
      " lr:  0.001\n",
      " stacks:  10\n",
      " k:  2\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for hidden_size, n_layers, sgd_lr, n_stack, k in \\\n",
    "    product(hidden_sizes, hidden_layers, sgd_lrs, n_stacks, ks):\n",
    "    print(\"=\" * 60)\n",
    "    print(\" units: \", hidden_size)\n",
    "    print(\" layers: \", n_layers)\n",
    "    print(\" lr: \", sgd_lr)\n",
    "    print(\" stacks: \", n_stack)\n",
    "    print(\" k: \", k)\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input graph and Layer graph are not the same: Tensor(\"rnn/while/TensorArrayReadV3:0\", shape=(?, 2), dtype=float32) is not from the passed-in graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m         self._graph = ops._get_graph_from_inputs(nest.flatten(inputs),  # pylint: disable=protected-access\n\u001b[0;32m--> 341\u001b[0;31m                                                  graph=self._graph)\n\u001b[0m\u001b[1;32m    342\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5665\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5666\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"rnn/while/TensorArrayReadV3:0\", shape=(?, 2), dtype=float32) is not from the passed-in graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dea32d7857e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 n_stack = n_stack, k = k)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecurrentWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Learning-Iterative-Image-Reconstruction/stackrnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, n_symbols, sgd_lr, hard_clip)\u001b[0m\n\u001b[1;32m    325\u001b[0m         outputs, states = tf.nn.dynamic_rnn(cell, self.symbols,\n\u001b[1;32m    326\u001b[0m                                             \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                                             time_major = True)\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# add linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3289\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3291\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3002\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3004\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3005\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2937\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m   2938\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3258\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3259\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3260\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    838\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_attrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m                                                  graph=self._graph)\n\u001b[1;32m    342\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input graph and Layer graph are not the same: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input graph and Layer graph are not the same: Tensor(\"rnn/while/TensorArrayReadV3:0\", shape=(?, 2), dtype=float32) is not from the passed-in graph."
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "\n",
    "        if model == \"srnn\":\n",
    "            cell = StackRNNCell(hidden_size, no_op = False,\n",
    "                                n_stack = n_stack, k = k)\n",
    "\n",
    "        model = RecurrentWrapper(cell, sgd_lr = sgd_lr)\n",
    "\n",
    "        sess = tf.Session()\n",
    "        sess.run([tf.global_variables_initializer(),\n",
    "                  tf.local_variables_initializer()])\n",
    "\n",
    "        n_max_train_ = 5\n",
    "        for i in range(n_iterations):\n",
    "            if i % 5 == 4:\n",
    "                n_max_train_ = min(n_max_train_ + 1, n_max_train)\n",
    "          \n",
    "            losses = []\n",
    "            for j in range(n_img_per_iter):\n",
    "                symbols_batch, targets_batch, _ = image_label[j],image_train[j]\n",
    "                current_loss, _ = sess.run(\n",
    "                    [model.loss, model.train_op],\n",
    "                    feed_dict = { model.symbols : symbols_batch,\n",
    "                                  model.targets : targets_batch })\n",
    "                losses.append(current_loss.mean())\n",
    "                \n",
    "            print(\"Number of iterations:\", i)\n",
    "            print(\" \", sum(losses) / len(losses))\n",
    "\n",
    "            # calculate accuracy for train + validation + test set\n",
    "            sequences_correct = []\n",
    "            for n in range(n_min, n_max_test + 1):\n",
    "                symbols_batch_, targets_batch_  =  image_label[n], image_train[n]\n",
    "                                \n",
    "                \n",
    "                predictions = sess.run(model.preds,\n",
    "                    feed_dict = { model.symbols : symbols_batch_ })\n",
    "\n",
    "                correct = all([np.argmax(t[0]) == p[0] for t, p, i in \\\n",
    "                               zip(targets_batch_, predictions)\n",
    "                               if i is True])\n",
    "                sequences_correct.append(correct)\n",
    "            print(\" \", sum(sequences_correct) / len(sequences_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "NNFL.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
